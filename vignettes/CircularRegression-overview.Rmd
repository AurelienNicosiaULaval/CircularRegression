---
title: "CircularRegression: An R Package for Regressing an Angle on Explanatory Variables"
subtitle: "Getting Started with CircularRegression"
author:
- "Aurélien Nicosia"
- "Louis‑Paul Rivest"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
    number_sections: true
    toc: true
    includes:
      in_header: theory-preamble_min.tex
geometry: margin=1in
vignette: >
  %\VignetteIndexEntry{Getting Started with CircularRegression}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
  bibliography: references.bib
editor_options:
chunk_output_type: console
bibliography: references.bib
biblio-style: authoryear
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
library(CircularRegression)
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(tibble)
library(circular)     # pour objets angulaires et outils de base
```

# Introduction

# The regression model of @Rivest16

## The conditional mean direction


This section reviews the regression model proposed in @Rivest16. Let $y$ denote the dependent angle and $x_1,\ldots, x_p$ represent explanatory angles.  To angle $x_j$ is associated a positive real variable $z_j$.  The proposed model is
\begin{equation}\label{eq:mod}
    y = \mu(\beta,x,z) + \epsilon.
\end{equation}
where $\mu(\beta,x,z)$ is the conditional mean direction of $y$ given $x$ and $z$ that depends on unknown parameters $\beta$  and $\epsilon$ is an random error term with a von Mises distribution centered at 0 with a concentration parameter $\kappa$ possibly dependent on $x$ and $z$. The vector
\begin{equation}
\label{vect}
\sum_{j=1}^p \beta_jz_j\left( \begin{array}{c} \cos(x_j) \\ \sin (x_j)
\end{array}\right) \quad \beta_j \in \Re, j=1,\ldots,p,
\end{equation}
plays a crucial role in defining the model. Its length is
\begin{equation}
\label{leng} \ell=\left[\left\{\sum_{j} \beta_j z_j\sin(x_j)\right\}^2+\left\{\sum_{j}  \beta_j z_j
\cos(x_j)\right\}^2\right]^{1/2},
\end{equation}
while its orientation is the predicted angle in \eqref{eq:mod},
\begin{equation}
\label{meand}
\mu(\beta,x,z)=
\arctan2\left\{\sum_{j=1}^p \beta_j z_j \sin(x_j),\sum_{j=1}^p
\beta_j z_j \cos(x_j)\right\},
\end{equation}
and $\arctan2(a,b)=\tan^{-1}(a/b)$ if $b>0$ and $\tan^{-1}(a/b)+ \pi$ if $b<0$.  Multiplying the parameters $\beta_j$ in \eqref{meand} by a positive constant does not change the orientation. To obtain identifiable parameters we set $\beta_1=1$, making $x_1$ the reference explanatory direction.  A  synthetic expression for mean direction (\ref{meand}) is
\begin{equation}\label{eq:mods}
y = 1 \times x_1:z_1 + x_2:z_2 + \ldots + x_p:z_p,
\end{equation}
where the operator $:$ denotes an interaction between an explanatory angle $x$ and its associated positive variable $z$. When $z_k=1$ one writes $x_k:z_k$ as $x_k$.

## The asymptotic distribution of $\hat \beta$ under homogeneous errors

For the homogeneous error model, the error concentration $\kappa>0$ does not depend on $x$ and $y$.  The estimator $\hat \beta$ is the parameter vector that maximizes the von Mises log-likelihood, $\kappa\sum_i\cos\{y_i- \mu(\beta,x_i,z_i)\}-n\log\{{\cal I}_0(\kappa)\}$ where ${\cal I}_\nu(\kappa)$ is a Bessel function of integer order for a non negative integer $\nu$.  The so-called MaxCosine, $MC=\sum_i\cos\{y_i- \mu(\hat \beta,x_i,z_i)\}/n$, is a measure of fit of the model; values close to 1 are associated with small residuals and a good fit. The  maximum likelihood estimator for $\kappa$ is $\hat \kappa=A^{-1}(MC)$ where $A(\kappa)={\cal I}_1(\kappa)/{\cal I}_0(\kappa)$  gives the mean resultant length of a von Mises distribution as a function of the concentration parameter $\kappa$.  The maximized log-likelihood is ${\cal L}_h(\hat \beta, \hat \kappa)$.

The robust estimator of the asymptotic variance of $\hat \beta$ proposed in @Rivest16 depends on the vectors $S_i$ and $C_i$ defined by
$$
S_i=\begin{pmatrix} z_{i2}\sin\{x_{i2}-\mu(\hat \beta,x_i,z_i)\}\\ \vdots \\ z_{ip}\sin\{x_{ip}-\mu(\hat\beta,x_i,z_i)\}\end{pmatrix} \mbox{~~and~~}
C_i=\begin{pmatrix} z_{i2}\cos\{x_{i2}-\mu(\hat\beta,x_i,z_i)\}\\ \vdots \\ z_{ip}\cos\{x_{ip}-\mu(\hat \beta,x_i,z_i)\}\end{pmatrix} .
$$
Observe that $S_i$ and $C_i$ have length $p-1$ since $\beta_1=1$ is not estimated. This robust covariance uses a sandwich variance formula.  It involves the matrix of second order partial derivatives of $\sum_i\cos\{y_i- \mu(\beta,x_i,z_i)\}$ with respect to $\beta$,
\begin{equation}\label{hata}
\hat  B= - \sum_{i=1}^n \frac{S_iS_i^\top}{\hat \ell_i^2} \cos\{y_i-\mu(\hat \beta,x_i,z_i)\}  - \sum_{i=1}^n \frac {\sin\{y_i-\mu(\hat \beta,x_i,z_i)\}}{\hat \ell_i^2} \left ( S_iC_i^\top+C_iS_i^\top\right),
\end{equation}
where $\hat \ell_i$  is the length given in \eqref{leng} for unit  $i$, evaluated at $\hat \beta$,  and the variance of the score function, $\sum S_i \sin\{y_i-\mu(\hat \beta,x_i,z_i)\} /\ell_i$. The sandwich estimator of the covariance matrix of $\hat \beta$ is
\begin{equation}\label{v1}
v_1(\hat \beta)=\hat B^{-1} \left\{ \sum_{i=1}^n \frac{\hat S_i \hat S_i^\top}{\hat \ell_i^2} \sin(y_i-\hat \mu_i)^2 \right\} \hat B^{-1}.
% c'est l'estimateur v_1 de la fonction de Sophie
\end{equation}

## The asymptotic distribution of $\hat \beta$ under concensus errors

It is convenient to parametrize the model with consensus in terms of positive parameters $\kappa=(\kappa_1,  \ldots, \kappa_p)^\top$. We use the notation $\ell_{i\kappa}$ to denote the length \eqref{leng} calculated for unit $i$ with the $\beta$ parameters replaced by the $\kappa$ parameters,
The loglikelihood function to estimate the $\kappa_j$'s is given by
$$
L(\kappa_1, \ldots, \kappa_p)= \sum_{j=1}^p \kappa_j  \sum_{i=1}^n z_{ij}\cos(y_i-x_{ij})- \sum_{i=1}^n \log\{{\cal I}_0(\ell_{i\kappa})\},
$$
where $\ell_{i\kappa}$ is the length $\ell_\kappa$ for the $i$th data point.  The maximized log-likelihood is labeled ${\cal L}_c( \hat \kappa)$.   A robust sandwich estimator for the covariance matrix of the estimator $\hat \kappa$  is expressed in terms of the Fisher information matrix
\begin{eqnarray*}
I(\kappa)   &=& \sum_{i=1}^n \left[\frac{A(\ell_{i\kappa})}{\ell_{i\kappa}}S_iS_i^\top +
   \{1- \frac{ A(\ell_{i\kappa})}{\ell_{i\kappa}}-A(\ell_{i\kappa})^2\} C_iC_i^\top\right],
\end{eqnarray*}
where  $S_i$ and $C_i$ are $p\times 1$ vectors of sines and cosines as defined in Section 1.2, and of the contribution of unit $i$ to the score vector
$$
\hat v_i=\begin{pmatrix}  \cos(y_i-x_{i1})-  \cos\{x_{i1}-\mu(\hat \kappa,x_i,z_i)\}  A(\hat \ell_{i\hat\kappa})\} \\ \vdots \\  \cos(y_i-x_{ip})-  \cos\{x_{ip}-\mu(\hat \kappa,x_i,z_i)\}  A(\hat \ell_{i\hat \kappa})\}
\end{pmatrix} \quad i=1,\ldots n.
$$
 A robust covariance matrix for the $p \times 1$ vector $\hat \kappa$ is
$$
v_1(\hat \kappa) = I(\hat \kappa)^{-1} \left( \sum_i \hat v_i \hat v_i^\top \right) I(\hat \kappa)^{-1}.
$$

To get estimators comparable to those obtained using homogeneous errors it is useful to define $\hat \beta_c= (\hat \kappa_2,\ldots, \hat \kappa_p)^\top/|\hat \kappa_1|$. The covariance matrix of $\hat \beta_c$ obtained by linearisation is
$v_1(\hat \beta_c)=A^\top v_1(\hat \kappa) A$, where
$$
A=\begin{pmatrix} -\hat \kappa_2/\hat \kappa_1^2 & -\hat \kappa_3/\hat \kappa_1^2 & \ldots &-\hat \kappa_p/\hat \kappa_1^2 \\
                    1/|\hat \kappa_1| & 0 &  \ldots & 0 \\
                    0 & 1/|\hat \kappa_1| &   \ldots & 0 \\
                    0 & 0 & \ddots    & 0  \\
                    0 & 0    & \ldots & 1/|\hat \kappa_1| \\
\end{pmatrix}.
$$



\section{Some special cases for model \eqref{eq:mod}}
Table \ref{tab:tab1} expresses in the general framework of equation \eqref{eq:mods} several circular regression models proposed in the literature when there are either a single auxiliary variable, either angle $x$ or covariate $z$ . The mean direction model, MeanDir, model $y = \mu+ \epsilon$ for $\mu \in [-\pi,\pi)$. It can written using expression \eqref{eq:mods} as long as $\mu \in [-\pi/2,\pi/2)$ the corresponding parameter is $\beta_2=\tan(\mu)$.  When $\mu$ is not in this interval one needs to change the reference angle to $x +\pi$. In a similar way the rotation regression model, RotMod, $y = x+ \mu+ \epsilon$ for $\mu \in [-\pi,\pi)$ can be expressed using
\eqref{eq:mods} as long as $\mu \in [-\pi/2,\pi/2)$ and $\beta_2$ is then equal to $\tan(\mu)$. When $x$ is an explanatory angle, adding $x+\pi/2$ to the model changes the explanaotry angle into $x+\theta$, for some angle $\theta$.  Indeed one has
\begin{align*}
\beta_2 \begin{pmatrix} \cos x \\ \sin x \end{pmatrix}+\beta_3 \begin{pmatrix} \cos (x+\pi/2) \\ \sin (x+\pi/2) \end{pmatrix} & =
 \begin{pmatrix} \cos x & -\sin x \\ \sin x &\cos x \end{pmatrix}\begin{pmatrix} \beta_2 \\ \beta_3 \end{pmatrix} \\
 &= \sqrt{\beta_2^2+\beta_3^2}\begin{pmatrix} \cos (x+\theta) \\ \sin (x+\theta) \end{pmatrix},
\end{align*}
where $\theta = \arctan2(\beta_3,\beta_2)$.

Changing the explanatory angle form $x$ to $-x$ leads to negative rotation model,  NRotMod in Table \ref{tab:tab1}.  The decentred predictor of @Rivest97 constructed with $x$, Decentred, or with $-x$, NDecentred, can also expressed in terms of the explanatory angles of Table \ref{tab:tab1}.  Model Presnell corresponds to the the proposal of @Presnell98  for a single continuous explanatory variable $z$.

\begin{table}%[htb!]
\caption{Some models for $y$, expressed using \eqref{eq:mods} constructed using a univariate predictor, either  $x$ or  $z$.  The reference direction is identified by a 1 while $\checkmark$ is used for additional explanatory variables }
\label{tab:tab1}
\centering
%\footnotesize\setlength\tabcolsep{2pt}
\begin{tabular}{ccccccccc}
\hline
&$0$&$\pi/2$&$x$&$x+\pi/2$&$-x$&$-x+\pi/2$&$0:z$&$\pi/2:z$\\
\hline
MeanDir & 1 & $\checkmark$ & & & & & & \\
RotMod &  &  & 1& $\checkmark$ & & & & \\
NRotMod &  &   & & & 1& $\checkmark$ & & \\
Decentred & $\checkmark$ & $\checkmark$ &1 & $\checkmark$& & & &  \\
NDecentred & $\checkmark$ & $\checkmark$ & & &1 & $\checkmark$& &  \\
JamSen & 1 & $\checkmark$& $\checkmark$ & $\checkmark$&$\checkmark$ &$\checkmark$  & & \\
Presnell & 1 & $\checkmark$  &  & & & &$\checkmark$ &$\checkmark$ \\
\hline
\end{tabular}
\end{table}

The circular regression models of Table \ref{tab:tab1} are special of the proposal in @jammalamadaka2001topics (JamSen in Table \ref{tab:tab1}).  Whose predicted angle
\begin{align}
\label{eq:JamSen}
\mu(\beta,x)=\arctan2 & \{\beta_2+(\beta_3-\beta_5) \sin x +(\beta_4+\beta_6) \cos x, \\
  & 1+ (\beta_3 + \beta_5) \cos x+(\beta_6-\beta_4) \sin x\}. \nonumber
\end{align}
The Moebius regression model of @Downs02 is also a special case of JamSen.  According to @polsen2015parametric
it involves two angles $\phi, \alpha \in [0,2\pi)$ and a dependence parameter $\omega \in (-1,1)$. Considering Table 5.1 of @polsen2015parametric the JamSen parameters in \eqref{eq:JamSen} for the Moebius regression model are $\beta_2=\tan \phi$ and
\begin{align*}
\beta_3&=\frac{1+\omega}{1-\omega}\frac{\cos(\alpha-\phi)}{2\cos(\phi)} \;
&\beta_4=\frac{1+\omega}{1-\omega}\frac{\cos(\alpha+\phi)}{2\cos(\phi)} \\
\beta_5&=\frac{1-\omega}{1+\omega}\frac{\cos(\alpha+\phi)}{2\cos(\phi)} \;
&\beta_6=\frac{1-\omega}{1+\omega}\frac{\cos(\alpha-\phi)}{2\cos(\phi)}.
\end{align*}
Under this model $\beta_3\beta_5/(\beta_4\beta_6)=1$.

\subsection{Model selection for a single independent angle $x$}
We now consider fitting model \eqref{eq:mod} to the Noshiro data set where $y$ is the direction of ground movement at a site, after an earthquake,  while $x$ is the direction of steepest descent at that site.  Following @Jones15 we removed data points with ties at $x=0, \pi/2$ leading to a sample of $n=678 $ sites where $(x,y)$ are measured.

To illustrate the impact of the choice of the reference explanatory angle $x_1$ on the fit, two JemSen models were fitted one with $x_1=\pi$, as the model with $x_1=0$ failed to converge, and the other with $x_1=x$.

AJOUTER ESTIMATION AVEC LES FONCTIONS DU PACKAGE (Refaire le tableau)

 The two models are equivalent: they give the same predicted angles $\mu(\hat \beta,x_i)$ and they both have $MC=0.5024$.  Indeed dividing the parameter estimate of the fit of the $x_1=\pi$ model, by the estimate for $x$, 5.72, gives the parameter estimates for the fit obtained with $x_1=x$. We want to use the p-values in Table \ref{tab:Nos} to identify important explanatory variables. In the $x_1=\pi$ fit one p-value is smaller than 5\%  while there are 3 with the other fit. 

Removing variables with p-values larger than 5\% in the $x_1=x$ fit leads to a model with $MC=0.5019$ with $\mu(\hat \beta,x_i)=\arctan2\{0.21+\sin(x)+.23\cos(x), -0.17 +\cos(x) +.23\sin(x)\}$ that is plotted in Figure \ref{fig:Nos}.


METTRE FIGURE DE LA PRÉDICTION





# Application: Bison movement data

The `bison` data frame contains directional observations (`y.dir`) along with
predictor summaries (`y.prec` and `y.prec2`) that characterize preceding animal
headings. The formulas used in this vignette follow the convention of placing the
circular response on the left-hand side.

## Angular regression model

The angular regression model links the response direction to previous directions
through trigonometric transformations. The example below fits the simplified
angular regression model with `y.dir` as the response and two predictors that
capture previous movement directions.

```{r angular-fit}
ang_fit_bison <- angular(y.dir ~ y.prec + y.prec2 + x.meadow + x.meadow:z.meadow + x.gap + x.gap:z.gap, data = bison)
ang_fit_bison
```

A summary provides parameter estimates and associated inference information.

```{r angular-summary}
summary(ang_fit_bison)
```




## Consensus regression model

The consensus model extends the angular regression framework by explicitly
modelling the concentration parameter. The following example fits a consensus
model using the same predictors.

```{r consensus-fit}
cons_fit_bison <- consensus(y.dir ~ y.prec + y.prec2 + x.meadow + x.meadow:z.meadow + x.gap + x.gap:z.gap, data = bison)
cons_fit_bison
```

You can inspect the estimated parameters and goodness-of-fit criteria via the
summary method.

```{r consensus-summary}
summary(cons_fit_bison)
```



## pick reference variable

In the homogeneous error model, the first angular predictor is the reference
angle. You can change the reference angle by reordering the predictors in the
formula. If the user wants to find the reference angle automatically, the
`pick_reference_angle()` function can be used. This function fits a consensus model
for every predictor and selects the one with the highest $\hat \beta$. For example, in the bison data set, `y.prec` is selected as the reference angle:

```{r}
pick_reference_angle(y.dir ~ y.prec + y.prec2 + x.meadow + x.meadow:z.meadow + x.gap + x.gap:z.gap, data = bison)
```

# Diagnostic tools


Diagnostic plots help assess the adequacy of the model by visualizing residuals
and fitted directions.

```{r angular-plot, fig.width=7, fig.height=6}
plot(ang_fit_bison)
```


For a more detailed diagnostic assessment, the plotting method provides a suite
of charts similar to those available for linear models.

```{r consensus-plot, fig.width=7, fig.height=6}
plot(cons_fit_bison)
```



# Simulation and model comparison

## Likelihood Ratio test

```{r}
fit_full <- angular(y.dir ~ y.prec + y.prec2 + x.gap + z.gap:x.gap, data = bison)
fit_reduced    <- angular(y.dir ~ y.prec + y.prec2, data = bison)
lrt_result  <- angular_lrtest(full = fit_full, reduced = fit_reduced)
print(lrt_result)
anova(fit_full, fit_reduced, test = "LRT")
```




# Application of angular regression model with random intercept

In the homogeneous–error formulation, the concentration parameter of the error distribution is assumed constant across all observations. This setting corresponds to a von Mises regression model in which the variability around the conditional mean direction does not depend on the explanatory variables. Rivest and Kato (2019) later extended this approach to account for *clustered circular data* by incorporating random effects and intra–cluster correlation within the homogeneous framework. Their model introduces a hierarchical structure where the mean direction combines a fixed–effects component, denoted \(\mu_{ij}(\beta)\), and a cluster–specific random intercept \(a_i\) following a von Mises distribution. This extension provides a natural way to model repeated or spatially correlated angular observations, while preserving the analytical simplicity of the homogeneous–error von Mises likelihood. The homogeneous model with a random intercept thus forms the foundation for more general mixed–effects specifications in circular regression, offering both interpretability and robustness when data exhibit within–cluster dependence.



```{r, echo=FALSE}
data("Sandhopper", package = "CircularRegression")
dat <- Sandhopper
to_rad <- function(x) x * pi/180
for (v in c("LN1","LN2","LN3","LN4","LN5","Azimuth","DirW")) dat[[v]] <- to_rad(dat[[v]])
dat$Eye <- log(dat$Odmx*dat$Odmn) - log(dat$Osmx*dat$Osmn)

# Retenir les 59 individus sans NA comme dans l'annexe
keep <- c(1:14,16:49,51:53,57:64)
dat2 <- dat[keep, ]

# "Long" : 5 lignes par individu
long <- do.call(rbind, lapply(seq_len(nrow(dat2)), function(i) {
  data.frame(
    id   = i,
    Azimuth = dat2$Azimuth[i],
    DirW    = dat2$DirW[i],
    SpeedW  = dat2$SpeedW[i],
    Eye     = dat2$Eye[i],
    Rep     = 0:4,
    LN      = as.numeric(dat2[i, paste0("LN", 1:5)])
  )
}))

# Modèle final de l'article (Eq. (11) et modèle restreint) :
# y ~ Azimuth + DirW + 0 + DirW:SpeedW + 0:Eye + (pi/2):Eye + (pi/2):Rep
# On réutilise la grammaire "x:z" de angular()
long$Zero   <- 0
long$Pi2    <- pi/2
```


The `angular_re()` function fits the random–intercept model of Rivest and Kato (2019). The following example uses the `Sandhopper` dataset from the `CircularRegression` package, which contains directional observations of sandhoppers along with various predictors. The dataset includes repeated measurements for each individual sandhopper, making it suitable for a mixed-effects model.

```{r}
fit <- angular_re(
  LN ~ Azimuth + DirW + Zero + DirW:SpeedW + Zero:Eye + Pi2:Eye + Pi2:Rep,
  data = long,
  cluster = long$id
)
print(fit)

# Résumés utiles
coef(fit)
vcov(fit)                 # SE modèle
vcov(fit, robust = TRUE)  # SE sandwich
head(fit$ranef)          # prédicteurs a_hat


# flèches avec longueur A1(kappa_a) (interprétable)
plot_ranef.angular_re(fit)

# longueur unitaire + labels de grappes
plot_ranef.angular_re(fit, scale = "unit", labels = TRUE)

## Rosaces (deux panneaux)
plot(fit, which = "both")             # fixed + conditional
plot(fit, which = "fixed")
plot(fit, which = "conditional", points = FALSE)





```

## prediction

```{r}
## Prédictions
library(circular)
new_df <- data.frame(
  LN = rvonmises(5, mu = 0, kappa = 1), # ex: 5 valeurs aléatoires
  Azimuth = rep(to_rad(45), 5),       # ex: 45° en radians
  DirW    = rep(to_rad(90), 5),       # ex: 90°
  Zero    = 0,                        # variable "constante"
  SpeedW  = rep(0.5, 5),              # ex: vitesse du vent
  Eye     = rep(mean(long$Eye), 5),   # ex: utiliser moyenne observée
  Pi2     = pi/2,
  Rep     = 0:4                       # répétitions
)
# marginales (nouvelle grappe)
mu_new <- predict(fit, newdata = new_df, type = "marginal")

# conditionnelles pour des observations appartenant à des grappes connues
mu_cond <- predict(fit, newdata = long, cluster = long$id,
                   type = "conditional")

# conditionnelles avec un a_hat imposé (p.ex. scénario)
mu_scenario <- predict(fit, newdata = new_df, type = "conditional", a_hat = 0.3)


```




# References


\bibliography{references}

