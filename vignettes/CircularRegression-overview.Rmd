---
title: "CircularRegression: An R Package for Regressing an Angle on Explanatory Variables"
subtitle: "Getting Started with CircularRegression"
author:
- "Aurélien Nicosia"
- "Louis‑Paul Rivest"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
    number_sections: true
    toc: true
    includes:
      in_header: theory-preamble_min.tex
geometry: margin=1in
vignette: >
  %\VignetteIndexEntry{Getting Started with CircularRegression}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
  bibliography: references.bib
editor_options:
chunk_output_type: console
bibliography: references.bib
biblio-style: authoryear
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
library(CircularRegression)
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(tibble)
library(circular)     # pour objets angulaires et outils de base
```

# Introduction


# Angular regression in R: a concise review 

This section surveys angular (circular) regression methods available in R and positions the package `CircularRegression` within that landscape. We focus on models for a circular response (angles on \([-π, π)\) or \([0, 2π)\)), with linear and/or circular predictors, covering parametric, Bayesian, nonparametric and tree/ensemble approaches. For a broad background on directional statistics and software, see the invited review by Pewsey & García‑Portugués [@pewsey2021recent].

## A taxonomy of approaches in R

### Classical (likelihood‑based) parametric regression

**Von Mises GLM/VGLM family.** 
The von Mises distribution is the circular analogue of the normal. In R, the **VGAM** package exposes a `vonmises()` family for vector generalized linear models, allowing the mean direction (and optionally concentration) to depend on covariates via link functions [@yee2015VGAM; @VGAMpkg].

**Fisher–Lee style circular regression.**
The **circular** package implements `lm.circular()` for circular‑linear and circular‑circular regression, where a von Mises response is linked to predictors through transformations inspired by Fisher & Lee’s Biometrics paper [@fisher1992angular; @circularPkg].

**Projected (embedded) models and wrapped alternatives.**
The **Directional** package offers several likelihood‑based regressions with a circular outcome (e.g., `spml.reg`, `cipc.reg`, `gcpc.reg`), including implementations related to the spherically‑projected linear model and wrapped distributions [@Presnell1998; @tsagrisDirectional].

**Legacy functions.**
The **CircStats** package includes a classical `circ.reg()` routine for circular‑circular regression and many building blocks and tests for circular analysis [@circstatsPkg].

### Bayesian projected‑normal regression (with mixed effects)

The **bpnreg** package fits Bayesian projected‑normal models via MCMC, in both multiple‑regression (`bpnr`) and mixed‑effects (`bpnme`) forms. This covers fixed effects, random intercepts/slopes, and offers posterior summaries and Bayes factors [@bpnregManual; @bpnregCRAN; @nunezAntonio2014].

### Nonparametric regression for circular data

The **NPCirc** package implements kernel methods for circular regression in the three settings (circular‑linear, circular‑circular, linear‑circular) including Nadaraya–Watson and local‑linear smoothers, bandwidth selectors, significance tests and visualization tools [@oliveira2014npcirc; @NPCircCRAN].

### Distributional regression trees and random forests (von Mises)

The **circtree** package provides distributional trees and forests for circular responses, using the von Mises distribution at the leaves. This yields interpretable trees, automatic covariate selection and flexible non‑linear effects [@lang2020circtree; @circtreePkg].

### Spatial and spatio‑temporal circular modeling

While not regression in the narrow sense of modeling a circular mean with covariates, **CircSpaceTime** implements Bayesian (wrapped/projected Gaussian) models for spatial and spatio‑temporal interpolation and prediction of circular fields, which is useful when dependence over space/time is prominent [@circspacetimeCRAN; @jonaLasinio2020CSTS].


## Where `CircularRegression` fits

The `CircularRegression` package targets likelihood‑based angular regression, emphasizing the
general model of @Rivest16 and important extensions:

- **General angular regression with von Mises errors** — an interpretable additive representation
  of directional effects (e.g., attraction to targets, alignment with features), with identifiability
  and ML estimation machinery [@Rivest16].
  
- **Consensus-error model** — models the mean direction as a consensus (vector sum)
  of hypothesized directional effects [@Rivest16].
  
- **Particular (special‑case) models** — convenient wrappers corresponding to commonly used
  structures (e.g., mean-direction model, decentered‑predictor model, Presnell‑style embedding,
  Jammalamadaka–Sengupta–type forms).
  
- **Random‑intercept model** — accommodates clustered circular outcomes with a
  von Mises random intercept at the group level, following @rivestKato2019.

Advantages relative to existing R alternatives:

- **Interpretability** (directional components and consensus representation) beyond generic links,
  with clear ecological/biomechanical meaning [@Rivest16].
  
- **Likelihood‑based estimation and inference** compatible with von Mises errors (contrast with projected‑normal
  Bayesian inference in **bpnreg**).  
  
- **Built‑in clustered (random‑intercept) model** for repeated measures on groups [@rivestKato2019].

- **Convenience wrappers** for well‑known structures, helping users specify models without hand‑crafting
  trigonometric re‑parametrizations.

## Choosing between packages (quick guide)

- Prefer **CircularRegression** when you want an interpretable *angular* model with von Mises errors,
  consensus components, or a random‑intercept extension, and ML‑based inference [@@Rivest16; @rivestKato2019].
  
- Prefer **bpnreg** when you need rich **Bayesian** mixed‑effects modeling under the projected‑normal and
  Bayesian model comparison (Bayes factors) [@bpnregManual].
  
- Prefer **VGAM**/**circular**/**Directional** for classical parametric fits with von Mises/wrapped families or
  Fisher–Lee/embedded transforms, especially when you need GLM‑type predictors and offsets
  [@circularPkg; @VGAMpkg; @tsagrisDirectional].
  
- Prefer **NPCirc** for **nonparametric** smoothing when relationships are strongly non‑linear and you wish to
  avoid parametric assumptions [@oliveira2014npcirc].
  
- Prefer **circtree** for **interpretable trees/forests** with automated covariate selection and interaction capture
  [@lang2020circtree].
  
- Prefer **CircSpaceTime** when **spatial/spatio‑temporal dependence** is central and you need kriging/prediction
  on circular fields [@circspacetimeCRAN].

## Snapshot of R functionality (selected)

| Package            | Core model family                        | Response | Predictors | Mixed effects | Key functions                             |
|:------------------|:-----------------------------------------|:---------|:-----------|:--------------|:-------------------------------------------|
| circular          | Von Mises GLM‑like (Fisher–Lee links)    | circular | linear/circular | –          | `lm.circular()`                            |
| VGAM              | VGLM with `vonmises()`                   | circular | linear     | –             | `vglm(y ~ x, family = vonmises())`         |
| Directional       | SPML / wrapped models                    | circular | linear     | –             | `spml.reg()`, `gcpc.reg()`, `cipc.reg()`   |
| CircStats         | Classical circular‑circular regression    | circular | circular   | –             | `circ.reg()`                               |
| bpnreg            | Bayesian projected‑normal (MCMC)         | circular | linear     | Yes       | `bpnr()`, `bpnme()`                        |
| NPCirc            | Kernel (NW, local‑linear)                 | circular | linear/circular | –        | `kern.reg.*` functions                     |
| circtree          | Distributional trees/forests (von Mises)  | circular | linear     | –             | `circtree()`, `circforest()`               |
| CircSpaceTime     | Wrapped/projected GP (Bayesian)           | circular (field) | space/time | hier. | `CircSpaceTime()`                          |
| CircularRegression| **General angular + consensus + RI**      | circular | linear/circular | Only random intercept | `angular()`, `consensus()`, model wrappers |



# The regression model of @Rivest16

## The conditional mean direction


This section reviews the regression model proposed in @Rivest16. Let $y$ denote the dependent angle and $x_1,\ldots, x_p$ represent explanatory angles.  To angle $x_j$ is associated a positive real variable $z_j$.  The proposed model is
\begin{equation}\label{eq:mod}
    y = \mu(\beta,x,z) + \epsilon.
\end{equation}
where $\mu(\beta,x,z)$ is the conditional mean direction of $y$ given $x$ and $z$ that depends on unknown parameters $\beta$  and $\epsilon$ is an random error term with a von Mises distribution centered at 0 with a concentration parameter $\kappa$ possibly dependent on $x$ and $z$. The vector
\begin{equation}
\label{vect}
\sum_{j=1}^p \beta_jz_j\left( \begin{array}{c} \cos(x_j) \\ \sin (x_j)
\end{array}\right) \quad \beta_j \in \Re, j=1,\ldots,p,
\end{equation}
plays a crucial role in defining the model. Its length is
\begin{equation}
\label{leng} \ell=\left[\left\{\sum_{j} \beta_j z_j\sin(x_j)\right\}^2+\left\{\sum_{j}  \beta_j z_j
\cos(x_j)\right\}^2\right]^{1/2},
\end{equation}
while its orientation is the predicted angle in \eqref{eq:mod},
\begin{equation}
\label{meand}
\mu(\beta,x,z)=
\arctan2\left\{\sum_{j=1}^p \beta_j z_j \sin(x_j),\sum_{j=1}^p
\beta_j z_j \cos(x_j)\right\},
\end{equation}
and $\arctan2(a,b)=\tan^{-1}(a/b)$ if $b>0$ and $\tan^{-1}(a/b)+ \pi$ if $b<0$.  Multiplying the parameters $\beta_j$ in \eqref{meand} by a positive constant does not change the orientation. To obtain identifiable parameters we set $\beta_1=1$, making $x_1$ the reference explanatory direction.  A  synthetic expression for mean direction (\ref{meand}) is
\begin{equation}\label{eq:mods}
y = 1 \times x_1:z_1 + x_2:z_2 + \ldots + x_p:z_p,
\end{equation}
where the operator $:$ denotes an interaction between an explanatory angle $x$ and its associated positive variable $z$. When $z_k=1$ one writes $x_k:z_k$ as $x_k$.

## The asymptotic distribution of $\hat \beta$ under homogeneous errors

For the homogeneous error model, the error concentration $\kappa>0$ does not depend on $x$ and $y$.  The estimator $\hat \beta$ is the parameter vector that maximizes the von Mises log-likelihood, $\kappa\sum_i\cos\{y_i- \mu(\beta,x_i,z_i)\}-n\log\{{\cal I}_0(\kappa)\}$ where ${\cal I}_\nu(\kappa)$ is a Bessel function of integer order for a non negative integer $\nu$.  The so-called MaxCosine, $MC=\sum_i\cos\{y_i- \mu(\hat \beta,x_i,z_i)\}/n$, is a measure of fit of the model; values close to 1 are associated with small residuals and a good fit. The  maximum likelihood estimator for $\kappa$ is $\hat \kappa=A^{-1}(MC)$ where $A(\kappa)={\cal I}_1(\kappa)/{\cal I}_0(\kappa)$  gives the mean resultant length of a von Mises distribution as a function of the concentration parameter $\kappa$.  The maximized log-likelihood is ${\cal L}_h(\hat \beta, \hat \kappa)$.

The robust estimator of the asymptotic variance of $\hat \beta$ proposed in @Rivest16 depends on the vectors $S_i$ and $C_i$ defined by
$$
S_i=\begin{pmatrix} z_{i2}\sin\{x_{i2}-\mu(\hat \beta,x_i,z_i)\}\\ \vdots \\ z_{ip}\sin\{x_{ip}-\mu(\hat\beta,x_i,z_i)\}\end{pmatrix} \mbox{~~and~~}
C_i=\begin{pmatrix} z_{i2}\cos\{x_{i2}-\mu(\hat\beta,x_i,z_i)\}\\ \vdots \\ z_{ip}\cos\{x_{ip}-\mu(\hat \beta,x_i,z_i)\}\end{pmatrix} .
$$
Observe that $S_i$ and $C_i$ have length $p-1$ since $\beta_1=1$ is not estimated. This robust covariance uses a sandwich variance formula.  It involves the matrix of second order partial derivatives of $\sum_i\cos\{y_i- \mu(\beta,x_i,z_i)\}$ with respect to $\beta$,
\begin{equation}\label{hata}
\hat  B= - \sum_{i=1}^n \frac{S_iS_i^\top}{\hat \ell_i^2} \cos\{y_i-\mu(\hat \beta,x_i,z_i)\}  - \sum_{i=1}^n \frac {\sin\{y_i-\mu(\hat \beta,x_i,z_i)\}}{\hat \ell_i^2} \left ( S_iC_i^\top+C_iS_i^\top\right),
\end{equation}
where $\hat \ell_i$  is the length given in \eqref{leng} for unit  $i$, evaluated at $\hat \beta$,  and the variance of the score function, $\sum S_i \sin\{y_i-\mu(\hat \beta,x_i,z_i)\} /\ell_i$. The sandwich estimator of the covariance matrix of $\hat \beta$ is
\begin{equation}\label{v1}
v_1(\hat \beta)=\hat B^{-1} \left\{ \sum_{i=1}^n \frac{\hat S_i \hat S_i^\top}{\hat \ell_i^2} \sin(y_i-\hat \mu_i)^2 \right\} \hat B^{-1}.
% c'est l'estimateur v_1 de la fonction de Sophie
\end{equation}

## The asymptotic distribution of $\hat \beta$ under concensus errors

It is convenient to parametrize the model with consensus in terms of positive parameters $\kappa=(\kappa_1,  \ldots, \kappa_p)^\top$. We use the notation $\ell_{i\kappa}$ to denote the length \eqref{leng} calculated for unit $i$ with the $\beta$ parameters replaced by the $\kappa$ parameters,
The loglikelihood function to estimate the $\kappa_j$'s is given by
$$
L(\kappa_1, \ldots, \kappa_p)= \sum_{j=1}^p \kappa_j  \sum_{i=1}^n z_{ij}\cos(y_i-x_{ij})- \sum_{i=1}^n \log\{{\cal I}_0(\ell_{i\kappa})\},
$$
where $\ell_{i\kappa}$ is the length $\ell_\kappa$ for the $i$th data point.  The maximized log-likelihood is labeled ${\cal L}_c( \hat \kappa)$.   A robust sandwich estimator for the covariance matrix of the estimator $\hat \kappa$  is expressed in terms of the Fisher information matrix
\begin{eqnarray*}
I(\kappa)   &=& \sum_{i=1}^n \left[\frac{A(\ell_{i\kappa})}{\ell_{i\kappa}}S_iS_i^\top +
   \{1- \frac{ A(\ell_{i\kappa})}{\ell_{i\kappa}}-A(\ell_{i\kappa})^2\} C_iC_i^\top\right],
\end{eqnarray*}
where  $S_i$ and $C_i$ are $p\times 1$ vectors of sines and cosines as defined in Section 1.2, and of the contribution of unit $i$ to the score vector
$$
\hat v_i=\begin{pmatrix}  \cos(y_i-x_{i1})-  \cos\{x_{i1}-\mu(\hat \kappa,x_i,z_i)\}  A(\hat \ell_{i\hat\kappa})\} \\ \vdots \\  \cos(y_i-x_{ip})-  \cos\{x_{ip}-\mu(\hat \kappa,x_i,z_i)\}  A(\hat \ell_{i\hat \kappa})\}
\end{pmatrix} \quad i=1,\ldots n.
$$
 A robust covariance matrix for the $p \times 1$ vector $\hat \kappa$ is
$$
v_1(\hat \kappa) = I(\hat \kappa)^{-1} \left( \sum_i \hat v_i \hat v_i^\top \right) I(\hat \kappa)^{-1}.
$$

To get estimators comparable to those obtained using homogeneous errors it is useful to define $\hat \beta_c= (\hat \kappa_2,\ldots, \hat \kappa_p)^\top/|\hat \kappa_1|$. The covariance matrix of $\hat \beta_c$ obtained by linearisation is
$v_1(\hat \beta_c)=A^\top v_1(\hat \kappa) A$, where
$$
A=\begin{pmatrix} -\hat \kappa_2/\hat \kappa_1^2 & -\hat \kappa_3/\hat \kappa_1^2 & \ldots &-\hat \kappa_p/\hat \kappa_1^2 \\
                    1/|\hat \kappa_1| & 0 &  \ldots & 0 \\
                    0 & 1/|\hat \kappa_1| &   \ldots & 0 \\
                    0 & 0 & \ddots    & 0  \\
                    0 & 0    & \ldots & 1/|\hat \kappa_1| \\
\end{pmatrix}.
$$



# Some special cases for model \eqref{eq:mod}
Table \ref{tab:tab1} expresses in the general framework of equation \eqref{eq:mods} several circular regression models proposed in the literature when there are either a single auxiliary variable, either angle $x$ or covariate $z$ . The mean direction model, MeanDir, model $y = \mu+ \epsilon$ for $\mu \in [-\pi,\pi)$. It can written using expression \eqref{eq:mods} as long as $\mu \in [-\pi/2,\pi/2)$ the corresponding parameter is $\beta_2=\tan(\mu)$.  When $\mu$ is not in this interval one needs to change the reference angle to $x +\pi$. In a similar way the rotation regression model, RotMod, $y = x+ \mu+ \epsilon$ for $\mu \in [-\pi,\pi)$ can be expressed using
\eqref{eq:mods} as long as $\mu \in [-\pi/2,\pi/2)$ and $\beta_2$ is then equal to $\tan(\mu)$. When $x$ is an explanatory angle, adding $x+\pi/2$ to the model changes the explanaotry angle into $x+\theta$, for some angle $\theta$.  Indeed one has
\begin{align*}
\beta_2 \begin{pmatrix} \cos x \\ \sin x \end{pmatrix}+\beta_3 \begin{pmatrix} \cos (x+\pi/2) \\ \sin (x+\pi/2) \end{pmatrix} & =
 \begin{pmatrix} \cos x & -\sin x \\ \sin x &\cos x \end{pmatrix}\begin{pmatrix} \beta_2 \\ \beta_3 \end{pmatrix} \\
 &= \sqrt{\beta_2^2+\beta_3^2}\begin{pmatrix} \cos (x+\theta) \\ \sin (x+\theta) \end{pmatrix},
\end{align*}
where $\theta = \arctan2(\beta_3,\beta_2)$.

Changing the explanatory angle form $x$ to $-x$ leads to negative rotation model,  NRotMod in Table \ref{tab:tab1}.  The decentred predictor of @Rivest97 constructed with $x$, Decentred, or with $-x$, NDecentred, can also expressed in terms of the explanatory angles of Table \ref{tab:tab1}.  Model Presnell corresponds to the the proposal of @Presnell98  for a single continuous explanatory variable $z$.

\begin{table}%[htb!]
\caption{Some models for $y$, expressed using \eqref{eq:mods} constructed using a univariate predictor, either  $x$ or  $z$.  The reference direction is identified by a 1 while $\checkmark$ is used for additional explanatory variables }
\label{tab:tab1}
\centering
%\footnotesize\setlength\tabcolsep{2pt}
\begin{tabular}{ccccccccc}
\hline
&$0$&$\pi/2$&$x$&$x+\pi/2$&$-x$&$-x+\pi/2$&$0:z$&$\pi/2:z$\\
\hline
MeanDir & 1 & $\checkmark$ & & & & & & \\
RotMod &  &  & 1& $\checkmark$ & & & & \\
NRotMod &  &   & & & 1& $\checkmark$ & & \\
Decentred & $\checkmark$ & $\checkmark$ &1 & $\checkmark$& & & &  \\
NDecentred & $\checkmark$ & $\checkmark$ & & &1 & $\checkmark$& &  \\
JamSen & 1 & $\checkmark$& $\checkmark$ & $\checkmark$&$\checkmark$ &$\checkmark$  & & \\
Presnell & 1 & $\checkmark$  &  & & & &$\checkmark$ &$\checkmark$ \\
\hline
\end{tabular}
\end{table}

The circular regression models of Table \ref{tab:tab1} are special of the proposal in @jammalamadaka2001topics (JamSen in Table \ref{tab:tab1}).  Whose predicted angle
\begin{align}
\label{eq:JamSen}
\mu(\beta,x)=\arctan2 & \{\beta_2+(\beta_3-\beta_5) \sin x +(\beta_4+\beta_6) \cos x, \\
  & 1+ (\beta_3 + \beta_5) \cos x+(\beta_6-\beta_4) \sin x\}. \nonumber
\end{align}
The Moebius regression model of @Downs02 is also a special case of JamSen.  According to @polsen2015parametric
it involves two angles $\phi, \alpha \in [0,2\pi)$ and a dependence parameter $\omega \in (-1,1)$. Considering Table 5.1 of @polsen2015parametric the JamSen parameters in \eqref{eq:JamSen} for the Moebius regression model are $\beta_2=\tan \phi$ and
\begin{align*}
\beta_3&=\frac{1+\omega}{1-\omega}\frac{\cos(\alpha-\phi)}{2\cos(\phi)} \;
&\beta_4=\frac{1+\omega}{1-\omega}\frac{\cos(\alpha+\phi)}{2\cos(\phi)} \\
\beta_5&=\frac{1-\omega}{1+\omega}\frac{\cos(\alpha+\phi)}{2\cos(\phi)} \;
&\beta_6=\frac{1-\omega}{1+\omega}\frac{\cos(\alpha-\phi)}{2\cos(\phi)}.
\end{align*}
Under this model $\beta_3\beta_5/(\beta_4\beta_6)=1$.


## How to fit these special cases in the `CircularRegression` package

This section shows how to reproduce the models in Table \ref{tab:tab1} using the wrapper functions provided by the `CircularRegression` package.  
Each wrapper returns a list with three elements:
- `fit`: the fitted object returned by `angular()`;
- `data_aug`: the augmented data used internally (with explicit column names);
- `formula`: the exact formula passed to `angular()`.

Unless otherwise noted, replace `df`, `y`, `x`, and `z` with the actual column names in your data.

```{r, message=FALSE}
library(CircularRegression)

df = data.frame(y = bison$y.dir, x = bison$y.prec, z = bison$x.meadow)
```

### Mean direction model (MeanDir)

The model $y = \mu + \varepsilon$ with baseline direction $\mu$. Under the synthetic formulation, the parameter associated with $\tan_\mu$ corresponds to $\tan(\mu)$. If $\mu \in [-\pi/2, \pi/2)$, no re-centering is needed.

```{r}
# Fixed mean μ (single value)
fit_mean <- meanDirectionModel(
  data     = df,
  response = "y",
  mu0      = 0  # or any numeric scalar; if NULL, baseline 0 and tan_mu = π/2
)

fit_mean$formula         # formula actually used
head(fit_mean$data_aug)  # augmented data (mu0, tan_mu)
fit_mean$fit             # fitted object from angular()
```

If you prefer a vector of baselines `mu0` (same length as `df`), pass it directly; the wrapper will build the appropriate augmented data.

### Rotation model (RotMod) and negative rotation model (NRotMod)

RotMod uses only the pair $(x, x + \pi/2)$; NRotMod uses $(-x, -x + \pi/2)$. These are immediate two-column special cases. While there is no dedicated wrapper for RotMod/NRotMod, you can specify them explicitly as follows.

```{r}
# RotMod: $y \sim x + (x + \pi/2)$
df$x_plus_pi2 <- df$x + pi/2
form_rot <- y ~ x + x_plus_pi2
fit_rot <- angular(formula = form_rot, data = df)
fit_rot

# NRotMod: $y \sim (-x) + (-x + \pi/2)$
df$x_neg     <- -df$x
df$x_neg_pi2 <- df$x_neg + pi/2
form_nrot <- y ~ x_neg + x_neg_pi2
fit_nrot <- angular(formula = form_nrot, data = df)
fit_nrot
```

If you prefer a wrapper-only workflow, note that the Jammalamadaka–Sengupta wrapper below contains these two columns as a subset; RotMod/NRotMod can be viewed as constrained versions of that general case.

### Decentered predictor (Decentred) and negative decentered predictor (NDecentred)

The decentered predictor with angular $x$ is obtained with the `decentredPredictorModel()` wrapper. For the negative version, simply pass a precomputed column $x_{neg} = -x$ as `w`.

```{r}
# Decentred: $y \sim x + (x + \pi/2) + const0 + constPi2$
fit_decentred <- decentredPredictorModel(
  data     = df,
  response = "y",
  w        = "x"   # the actual column name in df
)
fit_decentred$formula
head(fit_decentred$data_aug)
fit_decentred$fit

# NDecentred: use w = -x via a new column
df$x_neg <- -df$x
fit_ndecentred <- decentredPredictorModel(
  data     = df,
  response = "y",
  w        = "x_neg"
)
fit_ndecentred$formula
head(fit_ndecentred$data_aug)
fit_ndecentred$fit
```

The wrapper automatically names augmented columns using the true name of `w`, for instance `x_plus_pi2`, `const0`, and `constPi2`. In NDecentred, the column names will reflect `x_neg` accordingly.

### Jammalamadaka–Sengupta (JamSen)

This wrapper builds the six-term expansion $(0, \pi/2, w, -w, w + \pi/2, -w + \pi/2)$ for a single angular predictor $w$.

```{r}
fit_jamsen <- jammalamadakaModel(
  data     = df,
  response = "y",
  w        = "x"
)
fit_jamsen$formula
head(fit_jamsen$data_aug)
fit_jamsen$fit
```

The augmented data will include the columns `x_orig`, `neg_x`, `x_pi2`, and neg_x_pi`, in addition to $const0$ and $constPi2$. As mentioned above, RotMod/NRotMod correspond to using only the pair $(x, x + \pi/2)$ or $(-x, -x + \pi/2)$ from this construction.

### Presnell

For a single non-circular covariate $z$, use the `presnellModel()` wrapper, which builds the interaction terms with the constants $0$ and $\pi/2$.

```{r}
fit_presnell <- presnellModel(
  data     = df,
  response = "y",
  w        = "z"  # 'z' is continuous (non-circular)
)
fit_presnell$formula
head(fit_presnell$data_aug)
fit_presnell$fit
```

**Notes and practical tips**

- In all wrappers, the argument `response` and the predictor `w` are the real column names in your data. The augmented column names are derived systematically from those real names (for example, `x_plus_pi2`, `neg_x`, or interactions like `const0:z`, `constPi2:z`).

- You can extract `fit$formula` to report the exact synthetic representation used, and `fit$data_aug` to inspect or reuse the constructed covariates.

- If a rotation baseline places $\mu$ outside $[-\pi/2, \pi/2)$, re-center as appropriate (for example, consider $x + \pi$) before calling the wrapper, or use a transformed column as the input `w`.


## Example of the Jammalamadaka and Sengupta model with earthquake data

We now consider fitting model \eqref{eq:mod} to the Noshiro data set where $y$ is the direction of ground movement at a site, after an earthquake,  while $x$ is the direction of steepest descent at that site.  Following @Jones15 we removed data points with ties at $x=0, \pi/2$ leading to a sample of $n=678 $ sites where $(x,y)$ are measured.

To illustrate the impact of the choice of the reference explanatory angle $x_1$ on the fit, two JemSen models were fitted one with $x_1=\pi$, as the model with $x_1=0$ failed to converge, and the other with $x_1=x$.

```{r Noshiro-fits}
data("noshiro", package = "CircularRegression")

# by default in Jammalamadaka model x1=0
fit_0 <- jammalamadakaModel(data = noshiro, response = "DIRDSC", w = "DIRMV")
fit_0$fit
fit_0$formula

# changing reference angle to pi/2
fit_2 <- angular(
  formula = DIRDSC ~
    neg_DIRMV_pi2 + DIRMV_orig + const0 + neg_DIRMV + DIRMV_pi2,
  data = fit_0$data_aug
)
fit_2

# changing reference angle to x
fit_x <- angular(
  formula = DIRDSC ~
    DIRMV_orig + const0 + constPi2 + neg_DIRMV + DIRMV_pi2 + neg_DIRMV_pi2,
  data = fit_0$data_aug
)
fit_x
```

AJOUTER ESTIMATION AVEC LES FONCTIONS DU PACKAGE (Refaire le tableau du papier de LP)

 The two models are equivalent: they give the same predicted angles $\mu(\hat \beta,x_i)$ and they both have $MC=0.5024$.  Indeed dividing the parameter estimate of the fit of the $x_1=\pi$ model, by the estimate for $x$, 5.72, gives the parameter estimates for the fit obtained with $x_1=x$. We want to use the p-values in Table \ref{tab:Nos} to identify important explanatory variables. In the $x_1=\pi$ fit one p-value is smaller than 5\%  while there are 3 with the other fit. 

Removing variables with p-values larger than 5\% in the $x_1=x$ fit leads to a model with $MC=0.5019$ with $\mu(\hat \beta,x_i)=\arctan2\{0.21+\sin(x)+.23\cos(x), -0.17 +\cos(x) +.23\sin(x)\}$ that is plotted in Figure \ref{fig:Nos}.


```{r Noshiro-plot, fig.width=7, fig.height=6}
ggplot(data = noshiro, aes(x = DIRMV - pi, y = DIRDSC - pi)) +
  geom_point() +
  stat_function(
    fun = function(x) {
      atan2(0.21 + sin(x) + 0.23 * cos(x), -0.17 + cos(x) + 0.23 * sin(x))
    },
    color = "blue",
    size = 1
  ) +
  labs(
    title = "Noshiro Data: Fitted Circular Regression Model",
    x = "Direction of steepest descent",
    y = "Direction of movement"
  ) +
  theme_minimal()
```




# Application: Bison movement data

The `bison` data frame contains directional observations (`y.dir`) along with
predictor summaries (`y.prec` and `y.prec2`) that characterize preceding animal
headings. The formulas used in this vignette follow the convention of placing the
circular response on the left-hand side.

## Angular regression model

The angular regression model links the response direction to previous directions through trigonometric transformations. The example below fits the simplified angular regression model with `y.dir` as the response and multiple predictors that capture previous movement directions.

```{r angular-fit}
ang_fit_bison <- angular(y.dir ~ y.prec + y.prec2 + x.meadow + x.meadow:z.meadow + x.gap + x.gap:z.gap, data = bison)
ang_fit_bison
```

A summary provides parameter estimates and associated inference information.

```{r angular-summary}
summary(ang_fit_bison)
```

## Reference angle in angular regression model

### Effect of reference angle

Choosing the right reference angle is crucial in angular regression. 

```{r}
fit_1 <- angular(y.dir ~ y.prec + x.meadow + x.gap, data = bison)
fit_2 <- angular(y.dir ~ x.meadow + x.gap +  y.prec, data = bison)
fit_1$parameters
fit_2$parameters
```

In this example, the parameter estimates differ significantly based on the choice of reference angle. In the first fit, `y.prec` is the reference angle, while in the second fit uses `x.meadow` as the reference. This choice impacts both the parameter estimates and their interpretations. In the second fit, the estimate for `y.prec` is larger than 1, suggesting a strong influence on the response direction and `y.prec` shoud be the reference angle. Moreover, the estimated beta for `x.gap` changes between the two fits, indicating that the choice of reference angle can affect the inference about other predictors as well.

### How to choose the right reference angle

In the homogeneous error model, the first angular predictor in the formula is the reference angle. You can change the reference angle by reordering the predictors in the formula. If the user wants to find the reference angle, the `pick_reference_angle()` function can be used. This function fits an angular model for every predictor and selects the one with the highest $\hat \kappa$ in the consensus model. 

For example, in the bison data set, `y.prec` is selected as the reference angle:
```{r}
pick_bison <- pick_reference_angle(
  formula = y.dir ~
    y.prec + y.prec2 + x.meadow + x.meadow:z.meadow + x.gap + x.gap:z.gap,
  data = bison
)
pick_bison
```



### Change intial values of $\beta$

By default, the angular regression model uses initial values of $\beta$ randomly generated between -1 and 1 for all predictors, since it considers that the right reference angle have been chosen. If $|\hat \beta| >>1$ , it may indicate that a different reference angle would be more appropriate. Getting good initial values is important for the convergence of the optimization algorithm. However, if prior knowledge suggests different starting points, you can specify custom initial values using the `initbeta` argument in the `angular()` function.


```{r, eval=FALSE}
set.seed(123)
n <- 200
df <- data.frame(
  x = runif(n, -pi, pi),   # angular predictor
  z = rnorm(n)             # linear predictor
)

# True parameters
beta_true <- c(beta_x = 1, beta_xpi2 = 5, beta_z = 3)

# Build the linear predictor η
eta <- beta_true["beta_x"] * df$x +
       beta_true["beta_xpi2"] * (df$x + pi/2) +
       beta_true["beta_z"] * df$z

# Simulate a circular response around η with von Mises noise
kappa <- 5  # concentration
eps   <- circular::rvonmises(n, mu = 0, kappa = kappa)
df$y  <- atan2(sin(eta + eps), cos(eta + eps))

# Synthetic columns for angular()
df$x_plus_pi2 <- df$x + pi/2

# Model to recover true parameters
form <- y ~  x + x_plus_pi2 + z

# BAD initialization: far from true values
fit_bad <- try(angular(formula = form, data = df),
               silent = TRUE)
fit_bad  # usually fails or gives unstable estimates

# GOOD initialization: close to true parameters
good_init <- c(5, 3)
fit_good <- angular(formula = form, data = df, initbeta = good_init)

# Compare results
print(fit_good)
```


## Consensus regression model

The consensus model extends the angular regression framework by explicitly modelling the concentration parameter. The following example fits a consensus model using the same predictors.

```{r consensus-fit}
cons_fit_bison <- consensus(y.dir ~ y.prec + y.prec2 + x.meadow + x.meadow:z.meadow + x.gap + x.gap:z.gap, data = bison)
cons_fit_bison
```

You can inspect the estimated parameters and goodness-of-fit criteria via the summary method.

```{r consensus-summary}
summary(cons_fit_bison)
```

Cons

## Multiple bison analysis

### Data

We use the `multiplebison` dataset (hourly steps) bundled with **CircularRegression**. 

```{r}
dat <- multiplebison
glimpse(dat)
```

For convenience we’ll define the core columns and convert angles (degrees → radians). Hours are integers in `[0, 23]`:

```{r}
df <- dat %>%
  transmute(
    time      = datetime_round_next,
    hour      = as.integer(heure),
    dir_1044  = `direction_1044-a`,  # adapt to your exact column naming if needed
    dir_1045  = `direction_1045-a`,
    dist_1044 = `distance_1044-a`,
    dist_1045 = `distance_1045-a`,
    dist_pair = distance,
    turn_1044 = turn_ang_1044,
    turn_1045 = turn_ang_1045
  )

# Some datasets store names with '-' or other symbols; fix if needed:
deg2rad <- function(d) d * pi / 180
rad2deg <- function(r) r * 180 / pi

df <- df %>%
  mutate(
    # circular angles in radians
    y_1044 = deg2rad(dir_1044),
    y_1045 = deg2rad(dir_1045),
    phi    = 2*pi*(hour %% 24)/24,
    logdist = log1p(dist_pair),
    zero= 0,
    pi2 = pi/2,
    phi_pi2 = phi + pi/2,
    m_phi = -phi,
    m_phi_pi2 = m_phi + pi2
  ) %>%
  filter(!is.na(y_1044), !is.na(y_1045), !is.na(hour))
```



## Regression of direction on hour of day

We now fit the four special cases model defined in Section XXXXX. The mean direction is modeled as the direction of a weighted sum of unit vectors pointing to targets (e.g., `phi`, `phi+π/2`, etc.), where`phi` represent the angular version of the hour of day. 


```{r, eval = FALSE}

fit_M0_1044 <- angular(formula = y_1044 ~ zero  +  pi2 , data  = df)
fit_MR_1044 <- angular(formula = y_1044 ~ phi  +  phi_pi2 , data  = df)
fit_MD_1044 <- angular(formula = y_1044 ~ phi  +  zero + pi2 + phi_pi2 , data  = df)
fit_MJS_1044 <- angular(formula = y_1044 ~ phi  +  zero + pi2 + phi_pi2 +m_phi +m_phi_pi2 , data  = df)



```

Visual comparison of fitted mean direction vs. empirical circular means by hour (replicates Fig. 3.5 qualitatively).

```{r}
# On refait le graphiques avec les 4 modèles
```

Residual diagnostics—rose diagrams to visually check concentration and symmetry:

```{r}
# code 
```

**Model comparison via a likelihood-ratio–style statistic.** We emulate the thesis’ test contrasting a 24-parameter saturated model (free mean by hour) with a parsimonious MJS fit, using the statistic 
\(T^2 = 2 n \, \hat{\kappa}_1 ( \bar{C}_1 - \bar{C}_0 )\). We estimate \(\kappa\) via `circular::est.kappa` on residuals. See Section 2.2.6 and Table 3.9.

```{r}
# code: on utilise notre fonction LRtest
```

## Inter-bison dependence


### Circular regression of one bison on the other (with hour and distance)

We fit a model where the mean direction of 1044-a is predicted from 1045-a’s current direction, with hour-of-day contributions (\( \phi, \phi \pm \pi/2 \)) and an interaction on the pair distance (through \(\log(1+\text{distance})\)). This follows the thesis Section 3.3.3 (Tables 3.16–3.17 and Fig. 3.8). 

```{r, eval=FALSE}

df = df %>% mutate(
  y_1045_pi2 = y_1045 + pi/2,
    y_1044_pi2 = y_1044 + pi/2

)

 fit <- consensus( y_1044 ~ y_1045 + y_1045_pi2 + phi + phi_pi2 + m_phi + m_phi_pi2 + zero +  pi2 + y_1045:logdist, data = df )
fit

 fitc <- consensus( y_1045 ~ y_1044 + y_1044_pi2 + phi + phi_pi2 + m_phi + m_phi_pi2 + zero + pi2 + y_1044:logdist, data = df )
 fit <- angular( y_1045 ~ y_1044 + y_1044_pi2 + phi + phi_pi2 + m_phi + m_phi_pi2 + zero + pi2 + y_1044:logdist, data = df , initbeta = fit$parambeta[,1] )
 


```

A quick visualization mirroring Fig. 3.8—predicted direction for 1044-a across values of 1045-a’s direction, at two hours and two distances:

```{r}
# code
```








# Application of angular regression model with random intercept

In the homogeneous–error formulation, the concentration parameter of the error distribution is assumed constant across all observations. This setting corresponds to a von Mises regression model in which the variability around the conditional mean direction does not depend on the explanatory variables. Rivest and Kato (2019) later extended this approach to account for *clustered circular data* by incorporating random effects and intra–cluster correlation within the homogeneous framework. Their model introduces a hierarchical structure where the mean direction combines a fixed–effects component, denoted \(\mu_{ij}(\beta)\), and a cluster–specific random intercept \(a_i\) following a von Mises distribution. This extension provides a natural way to model repeated or spatially correlated angular observations, while preserving the analytical simplicity of the homogeneous–error von Mises likelihood. The homogeneous model with a random intercept thus forms the foundation for more general mixed–effects specifications in circular regression, offering both interpretability and robustness when data exhibit within–cluster dependence.



```{r, echo=FALSE}
data("Sandhopper", package = "CircularRegression")
dat <- Sandhopper
to_rad <- function(x) x * pi/180
for (v in c("LN1","LN2","LN3","LN4","LN5","Azimuth","DirW")) dat[[v]] <- to_rad(dat[[v]])
dat$Eye <- log(dat$Odmx*dat$Odmn) - log(dat$Osmx*dat$Osmn)

# Retenir les 59 individus sans NA comme dans l'annexe
keep <- c(1:14,16:49,51:53,57:64)
dat2 <- dat[keep, ]

# "Long" : 5 lignes par individu
long <- do.call(rbind, lapply(seq_len(nrow(dat2)), function(i) {
  data.frame(
    id   = i,
    Azimuth = dat2$Azimuth[i],
    DirW    = dat2$DirW[i],
    SpeedW  = dat2$SpeedW[i],
    Eye     = dat2$Eye[i],
    Rep     = 0:4,
    LN      = as.numeric(dat2[i, paste0("LN", 1:5)])
  )
}))

# Modèle final de l'article (Eq. (11) et modèle restreint) :
# y ~ Azimuth + DirW + 0 + DirW:SpeedW + 0:Eye + (pi/2):Eye + (pi/2):Rep
# On réutilise la grammaire "x:z" de angular()
long$Zero   <- 0
long$Pi2    <- pi/2
```


The `angular_re()` function fits the random–intercept model of Rivest and Kato (2019). The following example uses the `Sandhopper` dataset from the `CircularRegression` package, which contains directional observations of sandhoppers along with various predictors. The dataset includes repeated measurements for each individual sandhopper, making it suitable for a mixed-effects model.

```{r}
fit <- angular_re(
  LN ~ Azimuth + DirW + Zero + DirW:SpeedW + Zero:Eye + Pi2:Eye + Pi2:Rep,
  data = long,
  cluster = long$id
)
print(fit)

# Résumés utiles
coef(fit)
vcov(fit)                 # SE modèle
vcov(fit, robust = TRUE)  # SE sandwich
head(fit$ranef)          # prédicteurs a_hat


# flèches avec longueur A1(kappa_a) (interprétable)
plot_ranef.angular_re(fit)

# longueur unitaire + labels de grappes
plot_ranef.angular_re(fit, scale = "unit", labels = TRUE)

## Rosaces (deux panneaux)
plot(fit, which = "both")             # fixed + conditional
plot(fit, which = "fixed")
plot(fit, which = "conditional", points = FALSE)





```

## prediction

```{r}
## Prédictions
library(circular)
new_df <- data.frame(
  LN = rvonmises(5, mu = 0, kappa = 1), # ex: 5 valeurs aléatoires
  Azimuth = rep(to_rad(45), 5),       # ex: 45° en radians
  DirW    = rep(to_rad(90), 5),       # ex: 90°
  Zero    = 0,                        # variable "constante"
  SpeedW  = rep(0.5, 5),              # ex: vitesse du vent
  Eye     = rep(mean(long$Eye), 5),   # ex: utiliser moyenne observée
  Pi2     = pi/2,
  Rep     = 0:4                       # répétitions
)
# marginales (nouvelle grappe)
mu_new <- predict(fit, newdata = new_df, type = "marginal")
mu_new
# conditionnelles pour des observations appartenant à des grappes connues
mu_cond <- predict(fit, newdata = long, cluster = long$id,
                   type = "conditional")
mu_cond
# conditionnelles avec un a_hat imposé (p.ex. scénario)
mu_scenario <- predict(fit, newdata = new_df, type = "conditional", a_hat = 0.3)
mu_scenario

```




# References


\bibliography{references}

