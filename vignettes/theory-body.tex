\thispagestyle{empty}
\begin{center} {\bf {CircularRegression an R-package for regressing an angle on explanatory variables}} \vspace{5mm}


% password jrss c labemo13
by

Aur\'{e}lien Nicosia and Louis-Paul Rivest \\ Department of Mathematics and Statistics\\ Universit\'e
Laval, Qu\'ebec\\  Qu\'ebec \\ Canada G1V 0A6\\

\vspace{.5cm}



\end{center}

\setlength{\baselineskip}{4ex}

\vspace{0.75cm}

%\begin{abstract} This article investigates angular regressions that express the angles of an animal's motion in terms of time varying directions and distances to environmental features that could influence its displacement.  The proposed mean direction is a compromise between several possible targets. Conditions for the identifiability of the regression parameters are provided.  Maximum likelihood estimators for the parameters are derived under two von Mises error structures. Robust, sandwich estimators of the parameter variance covariance matrix are obtained. The statistical methodology proposed in this paper is first used to reanalyze a classical data set on Periwinkle movement.  A second application investigates how bison trails are shaped by meadows and canopy gaps in Saskatchewan's Prince Albert National Park.  \end{abstract}

\noindent{\bf Keywords}:   Biased correlated random walk,  Identifiability, Multivariate statistics, Sandwich variance estimator, von Mises distribution




%\section{Introduction}
%
%%The Applications and Case Studies section publishes original articles that do one or more of the following:
%%
%%    For real datasets, present analyses that are statistically innovative as well as scientifically and practically relevant.
%%    Contribute substantially to a scientific field through the use of sound statistical methods.
%%    Present new and useful data, such as a new life table for a segment of the population or a new social or economical indicator.
%%    Using empirical tests, examine or illustrate for an important application the utility of a valuable statistical technique.
%%    Evaluate the quality of important data sources.
%
%%Note that careful analyses of data of substantive importance may be published in JASA even if there are no methodological innovations. It is, of course, essential that such data analyses be carried out using the best available methodology, that the substantive problem be important, and that the relation of the statistical findings to the underlying scientific questions be discussed thoroughly.
%
%In ecology the development of GPS tracking devices facilitates the collection of large data sets on animal movement.  In addition, data on an animal's environment is now obtained from satellite imaging or other remote sensing technologies. Data sets of several sources can be combined in a geographic information system to investigate statistically how the movement of an animal is driven by its environment. The field of movement ecology  (Holyoak et al. 2008) has experienced a rapid development in recent years, as more high quality data sets become available. Current applications of movement ecology include Vanak et al. (2013) who have shown how the movement of large African carnivores is driven by prey distribution and the location of competitors. See also Latombe et al. (2014) who demonstrated that large herbivores momentarily adjust their movements to increase their use of food-rich areas following the recent passage of predators.
%
%Biased correlated random walks (BCRW) are  stochastic processes that summarize animal movement in terms of a small number of parameters (Turchin, 1998; Codling et al. 2008). According to Behamou (2014, p. 269), \textit{BCRW is currently the most flexible and powerful discrete-step model of single-scale single mode animal movements as it combines long and short term attractiveness with various degrees of stochasticity}.   A BCRW postulates that the angle of the movement of an animal at a given time results from a compromise between a will to go forward (directional persistence) and a desire to move towards a specific attractive target (directional bias), such as a den or a place rich in nutriment.
%Thus constructing a statistical model to fit a BCRW involves the definition of a compromise between two angles, say $x$ and $y$.   Many ecological papers dealing with BCRW models (e.g., Schultz and Crone 2001; Fortin, Morales and Boyce 2005; Barton et al. 2009; McClintock et al. 2012) define this compromise through a convex combination of $x$ and $y$, $ \lambda x +(1-\lambda) y$,  for some $\lambda \in (0,1)$. This definition is lacking because adding, or subtracting, $2 \pi$ to either $x$ or $y$ changes the value of the compromise. This problem becomes more severe when constructing a compromise between more than two angles.
%
%From a statistical point of view, fitting the angular component of a BCRW involves a circular regression and the goal of this paper is to propose new multivariate angular regression models for the analysis of animal movement data.
%Fisher and Lee (1992, 1994) are early contributors to the construction of angular regression models. They suggest unwrapping the circle using a function that maps the interval $(-\pi, \pi)$ to the real axis. Presnell et al. (1998) highlight numerical difficulties with  Fisher and Lee's proposal and suggest alternative models involving the mean vector of an offset normal distribution.  These works are concerned with real explanatory variables $x$; they do not pay special attention to situations where $x$ is an angle.
%
%The expression \textit{circular-circular regression} is sometimes used to denote regression models where both
%the dependent and the explanatory variables are angles.   Rivest (1997), Downs and Mardia (2002) and Kato et al. (2008) consider models for a single univariate explanatory angle.  The first one predicts the $y$ angle using the direction of a weighted sum of the unit vector of angle $x$ plus a decentring vector while the other two use a M\"{o}bius transform of the $x$ angle as a predictor for the $y$ angle. To our knowledge multivariate
%circular-circular regression models have not been considered in the literature. However, Jammalamadaka and SenGupta (2001, p. 188) propose an approach that involves  separate regression models for the sine and  the
%cosine of the dependent angle $y$ that could be implemented in a multivariate set-up.
%
%This work proposes a new multivariate angular regression model for both angular and linear predictors. Such a model is needed to consider simultaneously the appeal of an arbitrary number of targets, and their respective distances to the animal,  when studying animal movement.  Although the new model is motivated by applications in movement ecology, it should find applications in other areas.  For instance, in meteorology where wind direction could be predicted using wind speed and wind direction measured at several observation stations.
%


\section{The regression model of \citet{Rivest16}}

\subsection{The conditional mean direction}


This section reviews the regression model proposed in \citet{Rivest16}. Let $y$ denote the dependent angle and $x_1,\ldots, x_p$ represent explanatory angles.  To angle $x_j$ is associated a positive real variable $z_j$.  The proposed model is
\begin{equation}\label{eq:mod}
    y = \mu(\beta,x,z) + \epsilon.
\end{equation}
where $\mu(\beta,x,z)$ is the conditional mean direction of $y$ given $x$ and $z$ that depends on unknown parameters $\beta$  and $\epsilon$ is an random error term with a von Mises distribution centered at 0 with a concentration parameter $\kappa$ possibly dependent on $x$ and $z$. The vector
\begin{equation}
\label{vect}
\sum_{j=1}^p \beta_jz_j\left( \begin{array}{c} \cos(x_j) \\ \sin (x_j)
\end{array}\right) \quad \beta_j \in \Re, j=1,\ldots,p,
\end{equation}
plays a crucial role in defining the model. Its length is
\begin{equation}
\label{leng} \ell=\left[\left\{\sum_{j} \beta_j z_j\sin(x_j)\right\}^2+\left\{\sum_{j}  \beta_j z_j
\cos(x_j)\right\}^2\right]^{1/2},
\end{equation}
while its orientation is the predicted angle in \eqref{eq:mod},
\begin{equation}
\label{meand}
\mu(\beta,x,z)=
\arctan2\left\{\sum_{j=1}^p \beta_j z_j \sin(x_j),\sum_{j=1}^p
\beta_j z_j \cos(x_j)\right\},
\end{equation}
and $\arctan2(a,b)=\tan^{-1}(a/b)$ if $b>0$ and $\tan^{-1}(a/b)+ \pi$ if $b<0$.  Multiplying the parameters $\beta_j$ in \eqref{meand} by a positive constant does not change the orientation. To obtain identifiable parameters we set $\beta_1=1$, making $x_1$ the reference explanatory direction.  A  synthetic expression for mean direction (\ref{meand}) is
\begin{equation}\label{eq:mods}
y = 1 \times x_1:z_1 + x_2:z_2 + \ldots + x_p:z_p,
\end{equation}
where the operator $:$ denotes an interaction between an explanatory angle $x$ and its associated positive variable $z$. When $z_k=1$ one writes $x_k:z_k$ as $x_k$.

\subsection{The asymptotic distribution of $\hat \beta$ under homogeneous errors}

For the homogeneous error model, the error concentration $\kappa>0$ does not depend on $x$ and $y$.  The estimator $\hat \beta$ is the parameter vector that maximizes the von Mises log-likelihood, $\kappa\sum_i\cos\{y_i- \mu(\beta,x_i,z_i)\}-n\log\{{\cal I}_0(\kappa)\}$ where ${\cal I}_\nu(\kappa)$ is a Bessel function of integer order for a non negative integer $\nu$.  The so-called MaxCosine, $MC=\sum_i\cos\{y_i- \mu(\hat \beta,x_i,z_i)\}/n$, is a measure of fit of the model; values close to 1 are associated with small residuals and a good fit. The  maximum likelihood estimator for $\kappa$ is $\hat \kappa=A^{-1}(MC)$ where $A(\kappa)={\cal I}_1(\kappa)/{\cal I}_0(\kappa)$  gives the mean resultant length of a von Mises distribution as a function of the concentration parameter $\kappa$.  The maximized log-likelihood is ${\cal L}_h(\hat \beta, \hat \kappa)$.

The robust estimator of the asymptotic variance of $\hat \beta$ proposed in \citet{Rivest16} depends on the vectors $S_i$ and $C_i$ defined by
$$
S_i=\begin{pmatrix} z_{i2}\sin\{x_{i2}-\mu(\hat \beta,x_i,z_i)\}\\ \vdots \\ z_{ip}\sin\{x_{ip}-\mu(\hat\beta,x_i,z_i)\}\end{pmatrix} \mbox{~~and~~}
C_i=\begin{pmatrix} z_{i2}\cos\{x_{i2}-\mu(\hat\beta,x_i,z_i)\}\\ \vdots \\ z_{ip}\cos\{x_{ip}-\mu(\hat \beta,x_i,z_i)\}\end{pmatrix} .
$$
Observe that $S_i$ and $C_i$ have length $p-1$ since $\beta_1=1$ is not estimated. This robust covariance uses a sandwich variance formula.  It involves the matrix of second order partial derivatives of $\sum_i\cos\{y_i- \mu(\beta,x_i,z_i)\}$ with respect to $\beta$,
\begin{equation}\label{hata}
\hat  B= - \sum_{i=1}^n \frac{S_iS_i^\top}{\hat \ell_i^2} \cos\{y_i-\mu(\hat \beta,x_i,z_i)\}  - \sum_{i=1}^n \frac {\sin\{y_i-\mu(\hat \beta,x_i,z_i)\}}{\hat \ell_i^2} \left ( S_iC_i^\top+C_iS_i^\top\right),
\end{equation}
where $\hat \ell_i$  is the length given in \eqref{leng} for unit  $i$, evaluated at $\hat \beta$,  and the variance of the score function, $\sum S_i \sin\{y_i-\mu(\hat \beta,x_i,z_i)\} /\ell_i$. The sandwich estimator of the covariance matrix of $\hat \beta$ is
\begin{equation}\label{v1}
v_1(\hat \beta)=\hat B^{-1} \left\{ \sum_{i=1}^n \frac{\hat S_i \hat S_i^\top}{\hat \ell_i^2} \sin(y_i-\hat \mu_i)^2 \right\} \hat B^{-1}.
% c'est l'estimateur v_1 de la fonction de Sophie
\end{equation}

\subsection{The asymptotic distribution of $\hat \beta$ under concensus errors}

It is convenient to parametrize the model with consensus in terms of positive parameters $\kappa=(\kappa_1,  \ldots, \kappa_p)^\top$. We use the notation $\ell_{i\kappa}$ to denote the length \eqref{leng} calculated for unit $i$ with the $\beta$ parameters replaced by the $\kappa$ parameters,
The loglikelihood function to estimate the $\kappa_j$'s is given by
$$
L(\kappa_1, \ldots, \kappa_p)= \sum_{j=1}^p \kappa_j  \sum_{i=1}^n z_{ij}\cos(y_i-x_{ij})- \sum_{i=1}^n \log\{{\cal I}_0(\ell_{i\kappa})\},
$$
where $\ell_{i\kappa}$ is the length $\ell_\kappa$ for the $i$th data point.  The maximized log-likelihood is labeled ${\cal L}_c( \hat \kappa)$.   A robust sandwich estimator for the covariance matrix of the estimator $\hat \kappa$  is expressed in terms of the Fisher information matrix
\begin{eqnarray*}
I(\kappa)   &=& \sum_{i=1}^n \left[\frac{A(\ell_{i\kappa})}{\ell_{i\kappa}}S_iS_i^\top +
   \{1- \frac{ A(\ell_{i\kappa})}{\ell_{i\kappa}}-A(\ell_{i\kappa})^2\} C_iC_i^\top\right],
\end{eqnarray*}
where  $S_i$ and $C_i$ are $p\times 1$ vectors of sines and cosines as defined in Section 1.2, and of the contribution of unit $i$ to the score vector
$$
\hat v_i=\begin{pmatrix}  \cos(y_i-x_{i1})-  \cos\{x_{i1}-\mu(\hat \kappa,x_i,z_i)\}  A(\hat \ell_{i\hat\kappa})\} \\ \vdots \\  \cos(y_i-x_{ip})-  \cos\{x_{ip}-\mu(\hat \kappa,x_i,z_i)\}  A(\hat \ell_{i\hat \kappa})\}
\end{pmatrix} \quad i=1,\ldots n.
$$
 A robust covariance matrix for the $p \times 1$ vector $\hat \kappa$ is
$$
v_1(\hat \kappa) = I(\hat \kappa)^{-1} \left( \sum_i \hat v_i \hat v_i^\top \right) I(\hat \kappa)^{-1}.
$$

To get estimators comparable to those obtained using homogeneous errors it is useful to define $\hat \beta_c= (\hat \kappa_2,\ldots, \hat \kappa_p)^\top/|\hat \kappa_1|$. The covariance matrix of $\hat \beta_c$ obtained by linearisation is
$v_1(\hat \beta_c)=A^\top v_1(\hat \kappa) A$, where
$$
A=\begin{pmatrix} -\hat \kappa_2/\hat \kappa_1^2 & -\hat \kappa_3/\hat \kappa_1^2 & \ldots &-\hat \kappa_p/\hat \kappa_1^2 \\
                    1/|\hat \kappa_1| & 0 &  \ldots & 0 \\
                    0 & 1/|\hat \kappa_1| &   \ldots & 0 \\
                    0 & 0 & \ddots    & 0  \\
                    0 & 0    & \ldots & 1/|\hat \kappa_1| \\
\end{pmatrix}.
$$


\section{Some special cases for model \eqref{eq:mod}}
Table \ref{tab:tab1} expresses in the general framework of equation \eqref{eq:mods} several circular regression models proposed in the literature when there are either a single auxiliary variable, either angle $x$ or covariate $z$ . The mean direction model, MeanDir, model $y = \mu+ \epsilon$ for $\mu \in [-\pi,\pi)$. It can written using expression \eqref{eq:mods} as long as $\mu \in [-\pi/2,\pi/2)$ the corresponding parameter is $\beta_2=\tan(\mu)$.  When $\mu$ is not in this interval one needs to change the reference angle to $x +\pi$. In a similar way the rotation regression model, RotMod, $y = x+ \mu+ \epsilon$ for $\mu \in [-\pi,\pi)$ can be expressed using
\eqref{eq:mods} as long as $\mu \in [-\pi/2,\pi/2)$ and $\beta_2$ is then equal to $\tan(\mu)$. When $x$ is an explanatory angle, adding $x+\pi/2$ to the model changes the explanaotry angle into $x+\theta$, for some angle $\theta$.  Indeed one has
\begin{align*}
\beta_2 \begin{pmatrix} \cos x \\ \sin x \end{pmatrix}+\beta_3 \begin{pmatrix} \cos (x+\pi/2) \\ \sin (x+\pi/2) \end{pmatrix} & =
 \begin{pmatrix} \cos x & -\sin x \\ \sin x &\cos x \end{pmatrix}\begin{pmatrix} \beta_2 \\ \beta_3 \end{pmatrix} \\
 &= \sqrt{\beta_2^2+\beta_3^2}\begin{pmatrix} \cos (x+\theta) \\ \sin (x+\theta) \end{pmatrix},
\end{align*}
where $\theta = \arctan2(\beta_3,\beta_2)$.

Changing the explanatory angle form $x$ to $-x$ leads to negative rotation model,  NRotMod in Table \ref{tab:tab1}.  The decentred predictor of \citet{Rivest97} constructed with $x$, Decentred, or with $-x$, NDecentred, can also expressed in terms of the explanatory angles of Table \ref{tab:tab1}.  Model Presnell corresponds to the the proposal of \cite{Presnell98}  for a single continuous explanatory variable $z$.

\begin{table}%[htb!]
\caption{Some models for $y$, expressed using \eqref{eq:mods} constructed using a univariate predictor, either  $x$ or  $z$.  The reference direction is identified by a 1 while $\checkmark$ is used for additional explanatory variables }
\label{tab:tab1}
\centering
%\footnotesize\setlength\tabcolsep{2pt}
\begin{tabular}{ccccccccc}
\hline
&$0$&$\pi/2$&$x$&$x+\pi/2$&$-x$&$-x+\pi/2$&$0:z$&$\pi/2:z$\\
\hline
MeanDir & 1 & $\checkmark$ & & & & & & \\
RotMod &  &  & 1& $\checkmark$ & & & & \\
NRotMod &  &   & & & 1& $\checkmark$ & & \\
Decentred & $\checkmark$ & $\checkmark$ &1 & $\checkmark$& & & &  \\
NDecentred & $\checkmark$ & $\checkmark$ & & &1 & $\checkmark$& &  \\
JamSen & 1 & $\checkmark$& $\checkmark$ & $\checkmark$&$\checkmark$ &$\checkmark$  & & \\
Presnell & 1 & $\checkmark$  &  & & & &$\checkmark$ &$\checkmark$ \\
\hline
\end{tabular}
\end{table}

The circular regression models of Table \ref{tab:tab1} are special of the proposal in \cite[chap. 8]{jammalamadaka2001topics} (JamSen in Table \ref{tab:tab1}).  Whose predicted angle
\begin{align}
\label{eq:JamSen}
\mu(\beta,x)=\arctan2 & \{\beta_2+(\beta_3-\beta_5) \sin x +(\beta_4+\beta_6) \cos x, \\
  & 1+ (\beta_3 + \beta_5) \cos x+(\beta_6-\beta_4) \sin x\}. \nonumber
\end{align}
The Moebius regression model of \cite{Downs02} is also a special case of JamSen.  According to \cite{polsen2015parametric}
it involves two angles $\phi, \alpha \in [0,2\pi)$ and a dependence parameter $\omega \in (-1,1)$. Considering Table 5.1 of \cite{polsen2015parametric} the JamSen parameters in \eqref{eq:JamSen} for the Moebius regression model are $\beta_2=\tan \phi$ and
\begin{align*}
\beta_3&=\frac{1+\omega}{1-\omega}\frac{\cos(\alpha-\phi)}{2\cos(\phi)} \;
&\beta_4=\frac{1+\omega}{1-\omega}\frac{\cos(\alpha+\phi)}{2\cos(\phi)} \\
\beta_5&=\frac{1-\omega}{1+\omega}\frac{\cos(\alpha+\phi)}{2\cos(\phi)} \;
&\beta_6=\frac{1-\omega}{1+\omega}\frac{\cos(\alpha-\phi)}{2\cos(\phi)}.
\end{align*}
Under this model $\beta_3\beta_5/(\beta_4\beta_6)=1$.

\subsection{Model selection for a single independent angle $x$}
We now consider fitting model \eqref{eq:mod} to the Noshiro data set where $y$ is the direction of ground movement at a site, after an earthquake,  while $x$ is the direction of steepest descent at that site.  Following \cite{Jones15} we removed data points with ties at $x=0, \pi/2$ leading to a sample of $n=678 $ sites where $(x,y)$ are measured.

To illustrate the impact of the choice of the reference explanatory angle $x_1$ on the fit, two JemSen models were fitted one with $x_1=\pi$, as the model with $x_1=0$ failed to converge, and the other with $x_1=x$.
\begin{table}[ht]
\caption{Two sets of parameter estimates, and their p-values, obtained when fitting JemSen model to the Noshiro data set }
\label{tab:Nos}
\centering
\begin{tabular}{crrrr}
  \hline
Reference Direction  &  \multicolumn{2} {c}{$x_1=x$} &  \multicolumn{2} {c}{$x_1=\pi$}\\
$x$-variable & estimate & p-value & estimate & p-value \\
  \hline
 0 & -0.17 & 0.02 & -1 & NA \\
  $\pi/2$ & 0.24  & 0.01 &1.35 & 0.14 \\
  $x$       &   1   &  NA   & 5.72 & 0.02 \\
  $x+ \pi/2$ & -0.05 & 0.42 & -0.28 & 0.48 \\
  $-x$ & 0.00 & 0.96 & 0.02 & 0.96 \\
  $-x+ \pi/2$  & 0.21 & 0.01 & 1.20 & 0.11 \\
   \hline
\end{tabular}
\end{table}
The two models are equivalent: they give the same predicted angles $ \mu(\hat \beta,x_i)$ and they both have $MC=0.5024$.  Indeed dividing the parameter estimate of the fit of the $x_1=\pi$ model, by the estimate for $x$, 5.72, gives the parameter estimates for the fit obtained with $x_1=x$. We want to use the p-values in Table \ref{tab:Nos} to identify important explanatory variables. In the $x_1=\pi$ fit one p-value is smaller than 5\%  while there are 3 with the other fit.

Removing variables with p-values larger than 5\% in the $x_1=x$ fit leads to a model with $MC=0.5019$ with $\mu(\hat \beta,x_i)=\arctan2\{0.21+\sin(x)+.23\cos(x), -0.17 +\cos(x) +.23\sin(x)\}$ that is plotted in Figure \ref{fig:Nos}.


\begin{figure}[h]
    \centering
    %\vspace{-1cm}
        \centering
        \includegraphics[width=0.95\linewidth, height=0.5\linewidth]{Noshiro_fit.pdf}
        \caption{Prediction curve for the Noshiro data set}
        \label{fig:Nos}
    \end{figure}





% The circular regression model of \cite[chap. 8]{jammalamadaka2001topics} (JamSen in Table \ref{tab:tab1})  whose predicted angle  $\mu(\beta,x)=\arctan\{\beta_2+(\beta_3-\beta_5) \sin x +(\beta_4+\beta_6) \cos x,1+ (\beta_3 + \beta_5) \cos x+(\beta_6-\beta_4) \sin x\}$.
% A simpler for $\mu(\beta,x)$ in terms of parameters $\gamma_2,\ldots, \gamma_6$ is
%  $\mu(\gamma,x)=\arctan\{\gamma_2+\gamma_3 \sin x +\gamma_4 \cos x,1+ \gamma_5 \cos x+\gamma_6 \sin x\}$.  The $5 \times 5$  matrix $A$ that transforms the $\beta$ parameters into $\gamma$ parameters is:
%  $$
%  A= \begin{pmatrix} 1 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & -1 &0 \\ 0 & 0 & 1 & 0 & 1 \\  0 & 1 & 0 & 1 &0 \\  0 & 0 & -1 & 0 & 1.
%  \end{pmatrix}
%  $$
% The estimator of the covariance matrix of the $\gamma$ parameter is therefore
% $$
% v_1(\hat \gamma) = A v_1(\hat \beta)A^\top.
% $$




\bibliographystyle{apalike}
\bibliography{KaRiv}
